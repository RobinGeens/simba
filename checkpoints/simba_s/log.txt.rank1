[05/05 12:42:08] train INFO: Namespace(fp32_resume=False, batch_size=128, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=24, pin_mem=True, world_size=2, dist_url='env://', token_label=True, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 12:42:09] train INFO: Creating model: simba_s
[05/05 12:42:16] train INFO: number of params: 26591088
[05/05 12:42:16] train INFO: Start training for 310 epochs
[05/05 12:49:56] train INFO: Namespace(fp32_resume=False, batch_size=128, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=24, pin_mem=True, world_size=2, dist_url='env://', token_label=True, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 12:49:57] train INFO: Creating model: simba_s
[05/05 12:50:04] train INFO: number of params: 26591088
[05/05 12:50:04] train INFO: Start training for 310 epochs
[05/05 12:54:15] train INFO: Namespace(fp32_resume=False, batch_size=128, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=24, pin_mem=True, world_size=2, dist_url='env://', token_label=False, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 12:54:17] train INFO: Creating model: simba_s
[05/05 12:54:24] train INFO: number of params: 26142088
[05/05 12:54:24] train INFO: Start training for 310 epochs
[05/05 12:54:54] train INFO: Epoch: [0]  [   0/5004]  eta: 1 day, 17:39:29  lr: 0.000001  loss: 7.0223 (7.0223)  time: 29.9700  data: 1.8116  max mem: 18147
[05/05 12:55:16] train INFO: Epoch: [0]  [  10/5004]  eta: 6:30:17  lr: 0.000001  loss: 6.9799 (6.9789)  time: 4.6890  data: 0.1649  max mem: 18364
[05/05 12:55:37] train INFO: Epoch: [0]  [  20/5004]  eta: 4:49:12  lr: 0.000001  loss: 6.9799 (6.9852)  time: 2.1572  data: 0.0002  max mem: 18364
[05/05 12:55:59] train INFO: Epoch: [0]  [  30/5004]  eta: 4:13:03  lr: 0.000001  loss: 7.0053 (6.9938)  time: 2.1525  data: 0.0002  max mem: 18364
[05/05 12:56:21] train INFO: Epoch: [0]  [  40/5004]  eta: 3:54:25  lr: 0.000001  loss: 6.9961 (6.9927)  time: 2.1529  data: 0.0001  max mem: 18364
[05/05 12:56:42] train INFO: Epoch: [0]  [  50/5004]  eta: 3:42:55  lr: 0.000001  loss: 6.9732 (6.9916)  time: 2.1535  data: 0.0002  max mem: 18364
[05/05 12:57:04] train INFO: Epoch: [0]  [  60/5004]  eta: 3:35:03  lr: 0.000001  loss: 6.9732 (6.9928)  time: 2.1517  data: 0.0002  max mem: 18364
[05/05 12:57:25] train INFO: Epoch: [0]  [  70/5004]  eta: 3:29:21  lr: 0.000001  loss: 6.9882 (6.9926)  time: 2.1530  data: 0.0001  max mem: 18364
[05/05 12:57:47] train INFO: Epoch: [0]  [  80/5004]  eta: 3:24:57  lr: 0.000001  loss: 6.9925 (6.9924)  time: 2.1545  data: 0.0001  max mem: 18364
[05/05 12:58:08] train INFO: Epoch: [0]  [  90/5004]  eta: 3:21:26  lr: 0.000001  loss: 6.9841 (6.9908)  time: 2.1531  data: 0.0001  max mem: 18364
[05/05 12:58:30] train INFO: Epoch: [0]  [ 100/5004]  eta: 3:18:33  lr: 0.000001  loss: 6.9737 (6.9910)  time: 2.1531  data: 0.0001  max mem: 18364
[05/05 12:58:51] train INFO: Epoch: [0]  [ 110/5004]  eta: 3:16:05  lr: 0.000001  loss: 6.9990 (6.9910)  time: 2.1520  data: 0.0001  max mem: 18364
[05/05 12:59:13] train INFO: Epoch: [0]  [ 120/5004]  eta: 3:14:00  lr: 0.000001  loss: 7.0007 (6.9909)  time: 2.1517  data: 0.0001  max mem: 18364
[05/05 12:59:34] train INFO: Epoch: [0]  [ 130/5004]  eta: 3:12:12  lr: 0.000001  loss: 6.9990 (6.9908)  time: 2.1550  data: 0.0001  max mem: 18364
[05/05 12:59:56] train INFO: Epoch: [0]  [ 140/5004]  eta: 3:10:34  lr: 0.000001  loss: 6.9646 (6.9885)  time: 2.1538  data: 0.0001  max mem: 18364
[05/05 13:00:17] train INFO: Epoch: [0]  [ 150/5004]  eta: 3:09:06  lr: 0.000001  loss: 6.9719 (6.9883)  time: 2.1512  data: 0.0001  max mem: 18364
[05/05 13:00:39] train INFO: Epoch: [0]  [ 160/5004]  eta: 3:07:47  lr: 0.000001  loss: 7.0026 (6.9898)  time: 2.1519  data: 0.0001  max mem: 18364
[05/05 13:01:00] train INFO: Epoch: [0]  [ 170/5004]  eta: 3:06:35  lr: 0.000001  loss: 7.0013 (6.9894)  time: 2.1522  data: 0.0001  max mem: 18364
[05/05 13:01:22] train INFO: Epoch: [0]  [ 180/5004]  eta: 3:05:28  lr: 0.000001  loss: 6.9863 (6.9893)  time: 2.1525  data: 0.0001  max mem: 18364
[05/05 13:01:43] train INFO: Epoch: [0]  [ 190/5004]  eta: 3:04:26  lr: 0.000001  loss: 6.9828 (6.9891)  time: 2.1521  data: 0.0002  max mem: 18364
[05/05 13:02:05] train INFO: Epoch: [0]  [ 200/5004]  eta: 3:03:28  lr: 0.000001  loss: 6.9893 (6.9887)  time: 2.1515  data: 0.0002  max mem: 18364
[05/05 13:02:26] train INFO: Epoch: [0]  [ 210/5004]  eta: 3:02:34  lr: 0.000001  loss: 6.9962 (6.9892)  time: 2.1527  data: 0.0002  max mem: 18364
[05/05 13:02:48] train INFO: Epoch: [0]  [ 220/5004]  eta: 3:01:42  lr: 0.000001  loss: 6.9965 (6.9891)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 13:03:10] train INFO: Epoch: [0]  [ 230/5004]  eta: 3:00:53  lr: 0.000001  loss: 6.9908 (6.9888)  time: 2.1526  data: 0.0001  max mem: 18364
[05/05 13:03:31] train INFO: Epoch: [0]  [ 240/5004]  eta: 3:00:06  lr: 0.000001  loss: 6.9900 (6.9886)  time: 2.1514  data: 0.0002  max mem: 18364
[05/05 13:03:53] train INFO: Epoch: [0]  [ 250/5004]  eta: 2:59:21  lr: 0.000001  loss: 6.9837 (6.9884)  time: 2.1508  data: 0.0002  max mem: 18364
[05/05 13:04:14] train INFO: Epoch: [0]  [ 260/5004]  eta: 2:58:39  lr: 0.000001  loss: 6.9837 (6.9882)  time: 2.1527  data: 0.0002  max mem: 18364
[05/05 13:04:36] train INFO: Epoch: [0]  [ 270/5004]  eta: 2:57:57  lr: 0.000001  loss: 6.9849 (6.9881)  time: 2.1515  data: 0.0002  max mem: 18364
[05/05 13:04:57] train INFO: Epoch: [0]  [ 280/5004]  eta: 2:57:17  lr: 0.000001  loss: 6.9808 (6.9876)  time: 2.1504  data: 0.0002  max mem: 18364
[05/05 13:05:19] train INFO: Epoch: [0]  [ 290/5004]  eta: 2:56:39  lr: 0.000001  loss: 6.9872 (6.9881)  time: 2.1535  data: 0.0002  max mem: 18364
[05/05 13:05:40] train INFO: Epoch: [0]  [ 300/5004]  eta: 2:56:01  lr: 0.000001  loss: 6.9890 (6.9878)  time: 2.1520  data: 0.0002  max mem: 18364
[05/05 13:06:02] train INFO: Epoch: [0]  [ 310/5004]  eta: 2:55:24  lr: 0.000001  loss: 6.9647 (6.9867)  time: 2.1504  data: 0.0002  max mem: 18364
[05/05 13:06:23] train INFO: Epoch: [0]  [ 320/5004]  eta: 2:54:48  lr: 0.000001  loss: 6.9647 (6.9867)  time: 2.1513  data: 0.0002  max mem: 18364
[05/05 13:06:45] train INFO: Epoch: [0]  [ 330/5004]  eta: 2:54:14  lr: 0.000001  loss: 6.9808 (6.9864)  time: 2.1528  data: 0.0002  max mem: 18364
[05/05 13:07:06] train INFO: Epoch: [0]  [ 340/5004]  eta: 2:53:40  lr: 0.000001  loss: 6.9819 (6.9865)  time: 2.1546  data: 0.0001  max mem: 18364
[05/05 13:07:28] train INFO: Epoch: [0]  [ 350/5004]  eta: 2:53:07  lr: 0.000001  loss: 6.9721 (6.9854)  time: 2.1538  data: 0.0001  max mem: 18364
[05/05 13:07:49] train INFO: Epoch: [0]  [ 360/5004]  eta: 2:52:35  lr: 0.000001  loss: 6.9518 (6.9851)  time: 2.1528  data: 0.0002  max mem: 18364
[05/05 13:08:11] train INFO: Epoch: [0]  [ 370/5004]  eta: 2:52:03  lr: 0.000001  loss: 6.9762 (6.9846)  time: 2.1524  data: 0.0002  max mem: 18364
[05/05 13:08:32] train INFO: Epoch: [0]  [ 380/5004]  eta: 2:51:31  lr: 0.000001  loss: 6.9593 (6.9841)  time: 2.1526  data: 0.0002  max mem: 18364
[05/05 13:08:54] train INFO: Epoch: [0]  [ 390/5004]  eta: 2:51:00  lr: 0.000001  loss: 6.9484 (6.9834)  time: 2.1520  data: 0.0002  max mem: 18364
[05/05 13:09:15] train INFO: Epoch: [0]  [ 400/5004]  eta: 2:50:30  lr: 0.000001  loss: 6.9571 (6.9830)  time: 2.1516  data: 0.0002  max mem: 18364
[05/05 13:09:37] train INFO: Epoch: [0]  [ 410/5004]  eta: 2:50:00  lr: 0.000001  loss: 6.9643 (6.9825)  time: 2.1514  data: 0.0002  max mem: 18364
[05/05 13:09:58] train INFO: Epoch: [0]  [ 420/5004]  eta: 2:49:30  lr: 0.000001  loss: 6.9708 (6.9823)  time: 2.1529  data: 0.0002  max mem: 18364
[05/05 13:10:20] train INFO: Epoch: [0]  [ 430/5004]  eta: 2:49:01  lr: 0.000001  loss: 6.9617 (6.9816)  time: 2.1531  data: 0.0002  max mem: 18364
[05/05 13:10:42] train INFO: Epoch: [0]  [ 440/5004]  eta: 2:48:32  lr: 0.000001  loss: 6.9565 (6.9811)  time: 2.1516  data: 0.0002  max mem: 18364
[05/05 13:11:03] train INFO: Epoch: [0]  [ 450/5004]  eta: 2:48:04  lr: 0.000001  loss: 6.9553 (6.9805)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 13:11:25] train INFO: Epoch: [0]  [ 460/5004]  eta: 2:47:35  lr: 0.000001  loss: 6.9513 (6.9797)  time: 2.1537  data: 0.0002  max mem: 18364
[05/05 13:11:46] train INFO: Epoch: [0]  [ 470/5004]  eta: 2:47:08  lr: 0.000001  loss: 6.9603 (6.9797)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 13:12:08] train INFO: Epoch: [0]  [ 480/5004]  eta: 2:46:40  lr: 0.000001  loss: 6.9750 (6.9795)  time: 2.1516  data: 0.0001  max mem: 18364
[05/05 13:12:29] train INFO: Epoch: [0]  [ 490/5004]  eta: 2:46:12  lr: 0.000001  loss: 6.9697 (6.9791)  time: 2.1511  data: 0.0002  max mem: 18364
[05/05 13:12:51] train INFO: Epoch: [0]  [ 500/5004]  eta: 2:45:45  lr: 0.000001  loss: 6.9619 (6.9789)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 13:13:12] train INFO: Epoch: [0]  [ 510/5004]  eta: 2:45:18  lr: 0.000001  loss: 6.9683 (6.9788)  time: 2.1520  data: 0.0002  max mem: 18364
[05/05 13:13:34] train INFO: Epoch: [0]  [ 520/5004]  eta: 2:44:51  lr: 0.000001  loss: 6.9683 (6.9784)  time: 2.1522  data: 0.0002  max mem: 18364
[05/05 13:13:55] train INFO: Epoch: [0]  [ 530/5004]  eta: 2:44:25  lr: 0.000001  loss: 6.9691 (6.9783)  time: 2.1525  data: 0.0002  max mem: 18364
[05/05 13:14:17] train INFO: Epoch: [0]  [ 540/5004]  eta: 2:43:59  lr: 0.000001  loss: 6.9661 (6.9782)  time: 2.1534  data: 0.0001  max mem: 18364
[05/05 13:14:38] train INFO: Epoch: [0]  [ 550/5004]  eta: 2:43:32  lr: 0.000001  loss: 6.9661 (6.9781)  time: 2.1543  data: 0.0001  max mem: 18364
[05/05 13:15:00] train INFO: Epoch: [0]  [ 560/5004]  eta: 2:43:06  lr: 0.000001  loss: 6.9683 (6.9776)  time: 2.1519  data: 0.0002  max mem: 18364
[05/05 13:15:21] train INFO: Epoch: [0]  [ 570/5004]  eta: 2:42:41  lr: 0.000001  loss: 6.9652 (6.9773)  time: 2.1529  data: 0.0002  max mem: 18364
[05/05 13:15:43] train INFO: Epoch: [0]  [ 580/5004]  eta: 2:42:15  lr: 0.000001  loss: 6.9660 (6.9773)  time: 2.1548  data: 0.0002  max mem: 18364
[05/05 13:16:04] train INFO: Epoch: [0]  [ 590/5004]  eta: 2:41:49  lr: 0.000001  loss: 6.9660 (6.9770)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 13:16:26] train INFO: Epoch: [0]  [ 600/5004]  eta: 2:41:24  lr: 0.000001  loss: 6.9597 (6.9768)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 13:16:48] train INFO: Epoch: [0]  [ 610/5004]  eta: 2:40:59  lr: 0.000001  loss: 6.9556 (6.9765)  time: 2.1524  data: 0.0002  max mem: 18364
[05/05 13:17:09] train INFO: Epoch: [0]  [ 620/5004]  eta: 2:40:33  lr: 0.000001  loss: 6.9556 (6.9762)  time: 2.1522  data: 0.0002  max mem: 18364
[05/05 13:17:31] train INFO: Epoch: [0]  [ 630/5004]  eta: 2:40:08  lr: 0.000001  loss: 6.9618 (6.9760)  time: 2.1518  data: 0.0001  max mem: 18364
[05/05 13:17:52] train INFO: Epoch: [0]  [ 640/5004]  eta: 2:39:43  lr: 0.000001  loss: 6.9614 (6.9758)  time: 2.1517  data: 0.0001  max mem: 18364
[05/05 13:18:14] train INFO: Epoch: [0]  [ 650/5004]  eta: 2:39:18  lr: 0.000001  loss: 6.9590 (6.9757)  time: 2.1540  data: 0.0002  max mem: 18364
[05/05 13:18:35] train INFO: Epoch: [0]  [ 660/5004]  eta: 2:38:54  lr: 0.000001  loss: 6.9533 (6.9753)  time: 2.1550  data: 0.0001  max mem: 18364
[05/05 13:18:57] train INFO: Epoch: [0]  [ 670/5004]  eta: 2:38:29  lr: 0.000001  loss: 6.9471 (6.9753)  time: 2.1548  data: 0.0002  max mem: 18364
[05/05 13:19:18] train INFO: Epoch: [0]  [ 680/5004]  eta: 2:38:05  lr: 0.000001  loss: 6.9591 (6.9750)  time: 2.1532  data: 0.0002  max mem: 18364
[05/05 13:19:40] train INFO: Epoch: [0]  [ 690/5004]  eta: 2:37:40  lr: 0.000001  loss: 6.9591 (6.9748)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 13:20:01] train INFO: Epoch: [0]  [ 700/5004]  eta: 2:37:16  lr: 0.000001  loss: 6.9617 (6.9745)  time: 2.1541  data: 0.0002  max mem: 18364
[05/05 13:20:23] train INFO: Epoch: [0]  [ 710/5004]  eta: 2:36:52  lr: 0.000001  loss: 6.9617 (6.9743)  time: 2.1538  data: 0.0002  max mem: 18364
[05/05 13:20:44] train INFO: Epoch: [0]  [ 720/5004]  eta: 2:36:28  lr: 0.000001  loss: 6.9618 (6.9742)  time: 2.1553  data: 0.0002  max mem: 18364
[05/05 13:21:06] train INFO: Epoch: [0]  [ 730/5004]  eta: 2:36:04  lr: 0.000001  loss: 6.9575 (6.9740)  time: 2.1542  data: 0.0002  max mem: 18364
[05/05 13:21:28] train INFO: Epoch: [0]  [ 740/5004]  eta: 2:35:40  lr: 0.000001  loss: 6.9561 (6.9738)  time: 2.1537  data: 0.0002  max mem: 18364
[05/05 13:21:49] train INFO: Epoch: [0]  [ 750/5004]  eta: 2:35:15  lr: 0.000001  loss: 6.9486 (6.9734)  time: 2.1522  data: 0.0002  max mem: 18364
[05/05 13:22:11] train INFO: Epoch: [0]  [ 760/5004]  eta: 2:34:51  lr: 0.000001  loss: 6.9343 (6.9730)  time: 2.1518  data: 0.0002  max mem: 18364
[05/05 13:22:32] train INFO: Epoch: [0]  [ 770/5004]  eta: 2:34:28  lr: 0.000001  loss: 6.9313 (6.9724)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 13:22:54] train INFO: Epoch: [0]  [ 780/5004]  eta: 2:34:04  lr: 0.000001  loss: 6.9385 (6.9723)  time: 2.1548  data: 0.0002  max mem: 18364
[05/05 13:23:15] train INFO: Epoch: [0]  [ 790/5004]  eta: 2:33:40  lr: 0.000001  loss: 6.9511 (6.9721)  time: 2.1535  data: 0.0001  max mem: 18364
[05/05 13:23:37] train INFO: Epoch: [0]  [ 800/5004]  eta: 2:33:17  lr: 0.000001  loss: 6.9487 (6.9717)  time: 2.1540  data: 0.0001  max mem: 18364
[05/05 13:23:58] train INFO: Epoch: [0]  [ 810/5004]  eta: 2:32:53  lr: 0.000001  loss: 6.9466 (6.9714)  time: 2.1528  data: 0.0002  max mem: 18364
[05/05 13:24:20] train INFO: Epoch: [0]  [ 820/5004]  eta: 2:32:29  lr: 0.000001  loss: 6.9466 (6.9710)  time: 2.1520  data: 0.0002  max mem: 18364
[05/05 13:24:41] train INFO: Epoch: [0]  [ 830/5004]  eta: 2:32:06  lr: 0.000001  loss: 6.9466 (6.9708)  time: 2.1543  data: 0.0002  max mem: 18364
[05/05 13:25:03] train INFO: Epoch: [0]  [ 840/5004]  eta: 2:31:42  lr: 0.000001  loss: 6.9467 (6.9705)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 13:25:24] train INFO: Epoch: [0]  [ 850/5004]  eta: 2:31:19  lr: 0.000001  loss: 6.9462 (6.9702)  time: 2.1549  data: 0.0001  max mem: 18364
[05/05 13:25:46] train INFO: Epoch: [0]  [ 860/5004]  eta: 2:30:55  lr: 0.000001  loss: 6.9462 (6.9700)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 13:26:07] train INFO: Epoch: [0]  [ 870/5004]  eta: 2:30:32  lr: 0.000001  loss: 6.9613 (6.9699)  time: 2.1525  data: 0.0002  max mem: 18364
[05/05 13:26:29] train INFO: Epoch: [0]  [ 880/5004]  eta: 2:30:09  lr: 0.000001  loss: 6.9611 (6.9697)  time: 2.1547  data: 0.0002  max mem: 18364
[05/05 13:26:51] train INFO: Epoch: [0]  [ 890/5004]  eta: 2:29:45  lr: 0.000001  loss: 6.9554 (6.9696)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 13:27:12] train INFO: Epoch: [0]  [ 900/5004]  eta: 2:29:22  lr: 0.000001  loss: 6.9392 (6.9692)  time: 2.1525  data: 0.0002  max mem: 18364
[05/05 13:27:34] train INFO: Epoch: [0]  [ 910/5004]  eta: 2:28:59  lr: 0.000001  loss: 6.9392 (6.9690)  time: 2.1531  data: 0.0002  max mem: 18364
[05/05 13:27:55] train INFO: Epoch: [0]  [ 920/5004]  eta: 2:28:36  lr: 0.000001  loss: 6.9439 (6.9687)  time: 2.1536  data: 0.0002  max mem: 18364
[05/05 13:28:17] train INFO: Epoch: [0]  [ 930/5004]  eta: 2:28:13  lr: 0.000001  loss: 6.9404 (6.9684)  time: 2.1537  data: 0.0002  max mem: 18364
[05/05 13:28:38] train INFO: Epoch: [0]  [ 940/5004]  eta: 2:27:50  lr: 0.000001  loss: 6.9425 (6.9682)  time: 2.1536  data: 0.0002  max mem: 18364
[05/05 13:29:00] train INFO: Epoch: [0]  [ 950/5004]  eta: 2:27:26  lr: 0.000001  loss: 6.9431 (6.9679)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 13:29:21] train INFO: Epoch: [0]  [ 960/5004]  eta: 2:27:03  lr: 0.000001  loss: 6.9371 (6.9677)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 13:29:43] train INFO: Epoch: [0]  [ 970/5004]  eta: 2:26:40  lr: 0.000001  loss: 6.9371 (6.9674)  time: 2.1537  data: 0.0002  max mem: 18364
[05/05 13:30:04] train INFO: Epoch: [0]  [ 980/5004]  eta: 2:26:17  lr: 0.000001  loss: 6.9425 (6.9671)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 13:30:26] train INFO: Epoch: [0]  [ 990/5004]  eta: 2:25:55  lr: 0.000001  loss: 6.9452 (6.9669)  time: 2.1541  data: 0.0001  max mem: 18364
[05/05 13:30:47] train INFO: Epoch: [0]  [1000/5004]  eta: 2:25:32  lr: 0.000001  loss: 6.9328 (6.9665)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 13:31:09] train INFO: Epoch: [0]  [1010/5004]  eta: 2:25:09  lr: 0.000001  loss: 6.9370 (6.9663)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 13:31:31] train INFO: Epoch: [0]  [1020/5004]  eta: 2:24:46  lr: 0.000001  loss: 6.9386 (6.9661)  time: 2.1531  data: 0.0002  max mem: 18364
[05/05 13:31:52] train INFO: Epoch: [0]  [1030/5004]  eta: 2:24:23  lr: 0.000001  loss: 6.9438 (6.9660)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 13:32:14] train INFO: Epoch: [0]  [1040/5004]  eta: 2:24:00  lr: 0.000001  loss: 6.9437 (6.9656)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 13:32:35] train INFO: Epoch: [0]  [1050/5004]  eta: 2:23:37  lr: 0.000001  loss: 6.9343 (6.9654)  time: 2.1519  data: 0.0001  max mem: 18364
[05/05 13:32:57] train INFO: Epoch: [0]  [1060/5004]  eta: 2:23:15  lr: 0.000001  loss: 6.9386 (6.9652)  time: 2.1529  data: 0.0001  max mem: 18364
[05/05 13:33:18] train INFO: Epoch: [0]  [1070/5004]  eta: 2:22:52  lr: 0.000001  loss: 6.9337 (6.9649)  time: 2.1532  data: 0.0001  max mem: 18364
[05/05 13:33:40] train INFO: Epoch: [0]  [1080/5004]  eta: 2:22:29  lr: 0.000001  loss: 6.9371 (6.9647)  time: 2.1520  data: 0.0001  max mem: 18364
[05/05 13:34:01] train INFO: Epoch: [0]  [1090/5004]  eta: 2:22:06  lr: 0.000001  loss: 6.9423 (6.9644)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 13:34:23] train INFO: Epoch: [0]  [1100/5004]  eta: 2:21:44  lr: 0.000001  loss: 6.9354 (6.9641)  time: 2.1543  data: 0.0002  max mem: 18364
[05/05 13:34:44] train INFO: Epoch: [0]  [1110/5004]  eta: 2:21:21  lr: 0.000001  loss: 6.9306 (6.9640)  time: 2.1535  data: 0.0002  max mem: 18364
[05/05 13:35:06] train INFO: Epoch: [0]  [1120/5004]  eta: 2:20:58  lr: 0.000001  loss: 6.9425 (6.9638)  time: 2.1540  data: 0.0001  max mem: 18364
[05/05 13:35:27] train INFO: Epoch: [0]  [1130/5004]  eta: 2:20:36  lr: 0.000001  loss: 6.9425 (6.9637)  time: 2.1525  data: 0.0001  max mem: 18364
[05/05 13:35:49] train INFO: Epoch: [0]  [1140/5004]  eta: 2:20:13  lr: 0.000001  loss: 6.9378 (6.9633)  time: 2.1519  data: 0.0002  max mem: 18364
[05/05 13:36:10] train INFO: Epoch: [0]  [1150/5004]  eta: 2:19:50  lr: 0.000001  loss: 6.9312 (6.9630)  time: 2.1528  data: 0.0002  max mem: 18364
[05/05 13:36:32] train INFO: Epoch: [0]  [1160/5004]  eta: 2:19:28  lr: 0.000001  loss: 6.9381 (6.9630)  time: 2.1541  data: 0.0002  max mem: 18364
[05/05 13:36:53] train INFO: Epoch: [0]  [1170/5004]  eta: 2:19:05  lr: 0.000001  loss: 6.9532 (6.9628)  time: 2.1533  data: 0.0001  max mem: 18364
[05/05 13:37:15] train INFO: Epoch: [0]  [1180/5004]  eta: 2:18:43  lr: 0.000001  loss: 6.9568 (6.9627)  time: 2.1521  data: 0.0001  max mem: 18364
[05/05 13:37:36] train INFO: Epoch: [0]  [1190/5004]  eta: 2:18:20  lr: 0.000001  loss: 6.9594 (6.9627)  time: 2.1518  data: 0.0002  max mem: 18364
[05/05 13:37:58] train INFO: Epoch: [0]  [1200/5004]  eta: 2:17:58  lr: 0.000001  loss: 6.9459 (6.9625)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 13:38:20] train INFO: Epoch: [0]  [1210/5004]  eta: 2:17:35  lr: 0.000001  loss: 6.9440 (6.9625)  time: 2.1555  data: 0.0002  max mem: 18364
[05/05 13:38:41] train INFO: Epoch: [0]  [1220/5004]  eta: 2:17:13  lr: 0.000001  loss: 6.9388 (6.9623)  time: 2.1540  data: 0.0001  max mem: 18364
[05/05 13:39:03] train INFO: Epoch: [0]  [1230/5004]  eta: 2:16:51  lr: 0.000001  loss: 6.9359 (6.9620)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 13:39:24] train INFO: Epoch: [0]  [1240/5004]  eta: 2:16:28  lr: 0.000001  loss: 6.9356 (6.9618)  time: 2.1527  data: 0.0002  max mem: 18364
[05/05 13:39:46] train INFO: Epoch: [0]  [1250/5004]  eta: 2:16:06  lr: 0.000001  loss: 6.9444 (6.9617)  time: 2.1522  data: 0.0002  max mem: 18364
[05/05 13:40:07] train INFO: Epoch: [0]  [1260/5004]  eta: 2:15:43  lr: 0.000001  loss: 6.9381 (6.9614)  time: 2.1541  data: 0.0002  max mem: 18364
[05/05 13:40:29] train INFO: Epoch: [0]  [1270/5004]  eta: 2:15:21  lr: 0.000001  loss: 6.9336 (6.9613)  time: 2.1542  data: 0.0002  max mem: 18364
[05/05 13:40:50] train INFO: Epoch: [0]  [1280/5004]  eta: 2:14:59  lr: 0.000001  loss: 6.9431 (6.9612)  time: 2.1550  data: 0.0002  max mem: 18364
[05/05 13:41:12] train INFO: Epoch: [0]  [1290/5004]  eta: 2:14:36  lr: 0.000001  loss: 6.9387 (6.9610)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 13:41:33] train INFO: Epoch: [0]  [1300/5004]  eta: 2:14:14  lr: 0.000001  loss: 6.9359 (6.9608)  time: 2.1542  data: 0.0002  max mem: 18364
[05/05 13:41:55] train INFO: Epoch: [0]  [1310/5004]  eta: 2:13:52  lr: 0.000001  loss: 6.9331 (6.9606)  time: 2.1558  data: 0.0002  max mem: 18364
[05/05 13:42:17] train INFO: Epoch: [0]  [1320/5004]  eta: 2:13:29  lr: 0.000001  loss: 6.9282 (6.9603)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 13:42:38] train INFO: Epoch: [0]  [1330/5004]  eta: 2:13:07  lr: 0.000001  loss: 6.9217 (6.9601)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 13:43:00] train INFO: Epoch: [0]  [1340/5004]  eta: 2:12:45  lr: 0.000001  loss: 6.9458 (6.9601)  time: 2.1535  data: 0.0002  max mem: 18364
[05/05 13:43:21] train INFO: Epoch: [0]  [1350/5004]  eta: 2:12:22  lr: 0.000001  loss: 6.9452 (6.9599)  time: 2.1540  data: 0.0002  max mem: 18364
[05/05 13:43:43] train INFO: Epoch: [0]  [1360/5004]  eta: 2:12:00  lr: 0.000001  loss: 6.9321 (6.9597)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 13:44:04] train INFO: Epoch: [0]  [1370/5004]  eta: 2:11:38  lr: 0.000001  loss: 6.9343 (6.9595)  time: 2.1535  data: 0.0002  max mem: 18364
[05/05 13:44:26] train INFO: Epoch: [0]  [1380/5004]  eta: 2:11:16  lr: 0.000001  loss: 6.9343 (6.9593)  time: 2.1527  data: 0.0002  max mem: 18364
[05/05 13:44:47] train INFO: Epoch: [0]  [1390/5004]  eta: 2:10:53  lr: 0.000001  loss: 6.9333 (6.9592)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 13:45:09] train INFO: Epoch: [0]  [1400/5004]  eta: 2:10:31  lr: 0.000001  loss: 6.9334 (6.9590)  time: 2.1544  data: 0.0002  max mem: 18364
[05/05 13:45:30] train INFO: Epoch: [0]  [1410/5004]  eta: 2:10:09  lr: 0.000001  loss: 6.9216 (6.9588)  time: 2.1542  data: 0.0002  max mem: 18364
[05/05 13:45:52] train INFO: Epoch: [0]  [1420/5004]  eta: 2:09:47  lr: 0.000001  loss: 6.9202 (6.9585)  time: 2.1547  data: 0.0002  max mem: 18364
[05/05 13:46:13] train INFO: Epoch: [0]  [1430/5004]  eta: 2:09:25  lr: 0.000001  loss: 6.9321 (6.9584)  time: 2.1544  data: 0.0002  max mem: 18364
[05/05 13:46:35] train INFO: Epoch: [0]  [1440/5004]  eta: 2:09:02  lr: 0.000001  loss: 6.9447 (6.9583)  time: 2.1525  data: 0.0002  max mem: 18364
[05/05 13:46:57] train INFO: Epoch: [0]  [1450/5004]  eta: 2:08:40  lr: 0.000001  loss: 6.9373 (6.9581)  time: 2.1509  data: 0.0001  max mem: 18364
[05/05 13:47:18] train INFO: Epoch: [0]  [1460/5004]  eta: 2:08:18  lr: 0.000001  loss: 6.9340 (6.9579)  time: 2.1529  data: 0.0002  max mem: 18364
[05/05 13:47:40] train INFO: Epoch: [0]  [1470/5004]  eta: 2:07:56  lr: 0.000001  loss: 6.9350 (6.9578)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 13:48:01] train INFO: Epoch: [0]  [1480/5004]  eta: 2:07:34  lr: 0.000001  loss: 6.9352 (6.9577)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 13:48:23] train INFO: Epoch: [0]  [1490/5004]  eta: 2:07:11  lr: 0.000001  loss: 6.9356 (6.9576)  time: 2.1535  data: 0.0001  max mem: 18364
[05/05 13:48:44] train INFO: Epoch: [0]  [1500/5004]  eta: 2:06:49  lr: 0.000001  loss: 6.9413 (6.9575)  time: 2.1528  data: 0.0002  max mem: 18364
[05/05 13:49:06] train INFO: Epoch: [0]  [1510/5004]  eta: 2:06:27  lr: 0.000001  loss: 6.9341 (6.9574)  time: 2.1523  data: 0.0002  max mem: 18364
[05/05 13:49:27] train INFO: Epoch: [0]  [1520/5004]  eta: 2:06:05  lr: 0.000001  loss: 6.9301 (6.9572)  time: 2.1541  data: 0.0001  max mem: 18364
[05/05 13:49:49] train INFO: Epoch: [0]  [1530/5004]  eta: 2:05:43  lr: 0.000001  loss: 6.9275 (6.9570)  time: 2.1531  data: 0.0002  max mem: 18364
[05/05 13:50:10] train INFO: Epoch: [0]  [1540/5004]  eta: 2:05:21  lr: 0.000001  loss: 6.9275 (6.9569)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 13:50:32] train INFO: Epoch: [0]  [1550/5004]  eta: 2:04:59  lr: 0.000001  loss: 6.9327 (6.9567)  time: 2.1550  data: 0.0002  max mem: 18364
[05/05 13:50:53] train INFO: Epoch: [0]  [1560/5004]  eta: 2:04:36  lr: 0.000001  loss: 6.9386 (6.9566)  time: 2.1518  data: 0.0002  max mem: 18364
[05/05 13:51:15] train INFO: Epoch: [0]  [1570/5004]  eta: 2:04:14  lr: 0.000001  loss: 6.9361 (6.9564)  time: 2.1517  data: 0.0001  max mem: 18364
[05/05 13:51:36] train INFO: Epoch: [0]  [1580/5004]  eta: 2:03:52  lr: 0.000001  loss: 6.9343 (6.9563)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 13:51:58] train INFO: Epoch: [0]  [1590/5004]  eta: 2:03:30  lr: 0.000001  loss: 6.9343 (6.9562)  time: 2.1559  data: 0.0002  max mem: 18364
[05/05 13:52:20] train INFO: Epoch: [0]  [1600/5004]  eta: 2:03:08  lr: 0.000001  loss: 6.9268 (6.9560)  time: 2.1559  data: 0.0002  max mem: 18364
[05/05 13:52:41] train INFO: Epoch: [0]  [1610/5004]  eta: 2:02:46  lr: 0.000001  loss: 6.9467 (6.9561)  time: 2.1536  data: 0.0001  max mem: 18364
[05/05 13:53:03] train INFO: Epoch: [0]  [1620/5004]  eta: 2:02:24  lr: 0.000001  loss: 6.9456 (6.9559)  time: 2.1536  data: 0.0001  max mem: 18364
[05/05 13:53:24] train INFO: Epoch: [0]  [1630/5004]  eta: 2:02:02  lr: 0.000001  loss: 6.9315 (6.9558)  time: 2.1550  data: 0.0002  max mem: 18364
[05/05 13:53:46] train INFO: Epoch: [0]  [1640/5004]  eta: 2:01:40  lr: 0.000001  loss: 6.9315 (6.9556)  time: 2.1544  data: 0.0002  max mem: 18364
[05/05 13:54:07] train INFO: Epoch: [0]  [1650/5004]  eta: 2:01:18  lr: 0.000001  loss: 6.9308 (6.9555)  time: 2.1532  data: 0.0002  max mem: 18364
[05/05 13:54:29] train INFO: Epoch: [0]  [1660/5004]  eta: 2:00:56  lr: 0.000001  loss: 6.9245 (6.9552)  time: 2.1544  data: 0.0002  max mem: 18364
[05/05 13:54:50] train INFO: Epoch: [0]  [1670/5004]  eta: 2:00:34  lr: 0.000001  loss: 6.9258 (6.9551)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 13:55:12] train INFO: Epoch: [0]  [1680/5004]  eta: 2:00:12  lr: 0.000001  loss: 6.9353 (6.9550)  time: 2.1536  data: 0.0002  max mem: 18364
[05/05 13:55:33] train INFO: Epoch: [0]  [1690/5004]  eta: 1:59:50  lr: 0.000001  loss: 6.9261 (6.9548)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 13:55:55] train INFO: Epoch: [0]  [1700/5004]  eta: 1:59:28  lr: 0.000001  loss: 6.9274 (6.9546)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 13:56:17] train INFO: Epoch: [0]  [1710/5004]  eta: 1:59:06  lr: 0.000001  loss: 6.9205 (6.9544)  time: 2.1544  data: 0.0002  max mem: 18364
[05/05 13:56:38] train INFO: Epoch: [0]  [1720/5004]  eta: 1:58:44  lr: 0.000001  loss: 6.9238 (6.9543)  time: 2.1523  data: 0.0002  max mem: 18364
[05/05 13:57:00] train INFO: Epoch: [0]  [1730/5004]  eta: 1:58:22  lr: 0.000001  loss: 6.9362 (6.9541)  time: 2.1532  data: 0.0002  max mem: 18364
[05/05 13:57:21] train INFO: Epoch: [0]  [1740/5004]  eta: 1:58:00  lr: 0.000001  loss: 6.9271 (6.9540)  time: 2.1550  data: 0.0002  max mem: 18364
[05/05 13:57:43] train INFO: Epoch: [0]  [1750/5004]  eta: 1:57:38  lr: 0.000001  loss: 6.9405 (6.9539)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 13:58:04] train INFO: Epoch: [0]  [1760/5004]  eta: 1:57:16  lr: 0.000001  loss: 6.9405 (6.9537)  time: 2.1518  data: 0.0002  max mem: 18364
[05/05 13:58:26] train INFO: Epoch: [0]  [1770/5004]  eta: 1:56:54  lr: 0.000001  loss: 6.9328 (6.9537)  time: 2.1514  data: 0.0002  max mem: 18364
[05/05 13:58:47] train INFO: Epoch: [0]  [1780/5004]  eta: 1:56:32  lr: 0.000001  loss: 6.9285 (6.9535)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 13:59:09] train INFO: Epoch: [0]  [1790/5004]  eta: 1:56:10  lr: 0.000001  loss: 6.9185 (6.9534)  time: 2.1552  data: 0.0002  max mem: 18364
[05/05 13:59:30] train INFO: Epoch: [0]  [1800/5004]  eta: 1:55:48  lr: 0.000001  loss: 6.9208 (6.9532)  time: 2.1525  data: 0.0002  max mem: 18364
[05/05 13:59:52] train INFO: Epoch: [0]  [1810/5004]  eta: 1:55:26  lr: 0.000001  loss: 6.9216 (6.9531)  time: 2.1522  data: 0.0002  max mem: 18364
[05/05 14:00:13] train INFO: Epoch: [0]  [1820/5004]  eta: 1:55:04  lr: 0.000001  loss: 6.9327 (6.9530)  time: 2.1548  data: 0.0002  max mem: 18364
[05/05 14:00:35] train INFO: Epoch: [0]  [1830/5004]  eta: 1:54:42  lr: 0.000001  loss: 6.9290 (6.9528)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 14:00:56] train INFO: Epoch: [0]  [1840/5004]  eta: 1:54:20  lr: 0.000001  loss: 6.9193 (6.9526)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 14:01:18] train INFO: Epoch: [0]  [1850/5004]  eta: 1:53:58  lr: 0.000001  loss: 6.9236 (6.9525)  time: 2.1547  data: 0.0002  max mem: 18364
[05/05 14:01:40] train INFO: Epoch: [0]  [1860/5004]  eta: 1:53:37  lr: 0.000001  loss: 6.9270 (6.9524)  time: 2.1550  data: 0.0002  max mem: 18364
[05/05 14:02:01] train INFO: Epoch: [0]  [1870/5004]  eta: 1:53:15  lr: 0.000001  loss: 6.9260 (6.9523)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 14:02:23] train INFO: Epoch: [0]  [1880/5004]  eta: 1:52:53  lr: 0.000001  loss: 6.9359 (6.9522)  time: 2.1536  data: 0.0002  max mem: 18364
[05/05 14:02:44] train INFO: Epoch: [0]  [1890/5004]  eta: 1:52:31  lr: 0.000001  loss: 6.9359 (6.9521)  time: 2.1522  data: 0.0002  max mem: 18364
[05/05 14:03:06] train INFO: Epoch: [0]  [1900/5004]  eta: 1:52:09  lr: 0.000001  loss: 6.9135 (6.9518)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 14:03:27] train INFO: Epoch: [0]  [1910/5004]  eta: 1:51:47  lr: 0.000001  loss: 6.9096 (6.9517)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 14:03:49] train INFO: Epoch: [0]  [1920/5004]  eta: 1:51:25  lr: 0.000001  loss: 6.9205 (6.9516)  time: 2.1534  data: 0.0002  max mem: 18364
[05/05 14:04:10] train INFO: Epoch: [0]  [1930/5004]  eta: 1:51:03  lr: 0.000001  loss: 6.9231 (6.9514)  time: 2.1535  data: 0.0002  max mem: 18364
[05/05 14:04:32] train INFO: Epoch: [0]  [1940/5004]  eta: 1:50:41  lr: 0.000001  loss: 6.9303 (6.9513)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 14:04:53] train INFO: Epoch: [0]  [1950/5004]  eta: 1:50:19  lr: 0.000001  loss: 6.9354 (6.9512)  time: 2.1546  data: 0.0001  max mem: 18364
[05/05 14:05:15] train INFO: Epoch: [0]  [1960/5004]  eta: 1:49:57  lr: 0.000001  loss: 6.9280 (6.9511)  time: 2.1545  data: 0.0001  max mem: 18364
[05/05 14:05:37] train INFO: Epoch: [0]  [1970/5004]  eta: 1:49:36  lr: 0.000001  loss: 6.9157 (6.9509)  time: 2.1543  data: 0.0001  max mem: 18364
[05/05 14:05:58] train INFO: Epoch: [0]  [1980/5004]  eta: 1:49:14  lr: 0.000001  loss: 6.9105 (6.9507)  time: 2.1531  data: 0.0001  max mem: 18364
[05/05 14:06:20] train INFO: Epoch: [0]  [1990/5004]  eta: 1:48:52  lr: 0.000001  loss: 6.9172 (6.9506)  time: 2.1522  data: 0.0001  max mem: 18364
[05/05 14:06:41] train INFO: Epoch: [0]  [2000/5004]  eta: 1:48:30  lr: 0.000001  loss: 6.9194 (6.9504)  time: 2.1527  data: 0.0001  max mem: 18364
[05/05 14:07:03] train INFO: Epoch: [0]  [2010/5004]  eta: 1:48:08  lr: 0.000001  loss: 6.9243 (6.9503)  time: 2.1528  data: 0.0001  max mem: 18364
[05/05 14:07:24] train INFO: Epoch: [0]  [2020/5004]  eta: 1:47:46  lr: 0.000001  loss: 6.9260 (6.9502)  time: 2.1533  data: 0.0001  max mem: 18364
[05/05 14:07:46] train INFO: Epoch: [0]  [2030/5004]  eta: 1:47:24  lr: 0.000001  loss: 6.9261 (6.9501)  time: 2.1542  data: 0.0001  max mem: 18364
[05/05 14:08:07] train INFO: Epoch: [0]  [2040/5004]  eta: 1:47:02  lr: 0.000001  loss: 6.9220 (6.9500)  time: 2.1545  data: 0.0001  max mem: 18364
[05/05 14:08:29] train INFO: Epoch: [0]  [2050/5004]  eta: 1:46:41  lr: 0.000001  loss: 6.9244 (6.9499)  time: 2.1532  data: 0.0001  max mem: 18364
[05/05 14:08:50] train INFO: Epoch: [0]  [2060/5004]  eta: 1:46:19  lr: 0.000001  loss: 6.9165 (6.9497)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 14:09:12] train INFO: Epoch: [0]  [2070/5004]  eta: 1:45:57  lr: 0.000001  loss: 6.9071 (6.9495)  time: 2.1540  data: 0.0002  max mem: 18364
[05/05 14:09:33] train INFO: Epoch: [0]  [2080/5004]  eta: 1:45:35  lr: 0.000001  loss: 6.9126 (6.9494)  time: 2.1523  data: 0.0001  max mem: 18364
[05/05 14:09:55] train INFO: Epoch: [0]  [2090/5004]  eta: 1:45:13  lr: 0.000001  loss: 6.9313 (6.9493)  time: 2.1520  data: 0.0001  max mem: 18364
[05/05 14:10:16] train INFO: Epoch: [0]  [2100/5004]  eta: 1:44:51  lr: 0.000001  loss: 6.9250 (6.9492)  time: 2.1537  data: 0.0001  max mem: 18364
[05/05 14:10:38] train INFO: Epoch: [0]  [2110/5004]  eta: 1:44:29  lr: 0.000001  loss: 6.9250 (6.9491)  time: 2.1549  data: 0.0002  max mem: 18364
[05/05 14:11:00] train INFO: Epoch: [0]  [2120/5004]  eta: 1:44:08  lr: 0.000001  loss: 6.9394 (6.9491)  time: 2.1530  data: 0.0001  max mem: 18364
[05/05 14:11:21] train INFO: Epoch: [0]  [2130/5004]  eta: 1:43:46  lr: 0.000001  loss: 6.9223 (6.9490)  time: 2.1534  data: 0.0001  max mem: 18364
[05/05 14:11:43] train INFO: Epoch: [0]  [2140/5004]  eta: 1:43:24  lr: 0.000001  loss: 6.9163 (6.9488)  time: 2.1545  data: 0.0001  max mem: 18364
[05/05 14:12:04] train INFO: Epoch: [0]  [2150/5004]  eta: 1:43:02  lr: 0.000001  loss: 6.9267 (6.9488)  time: 2.1536  data: 0.0001  max mem: 18364
[05/05 14:12:26] train INFO: Epoch: [0]  [2160/5004]  eta: 1:42:40  lr: 0.000001  loss: 6.9294 (6.9487)  time: 2.1540  data: 0.0001  max mem: 18364
[05/05 14:12:47] train INFO: Epoch: [0]  [2170/5004]  eta: 1:42:18  lr: 0.000001  loss: 6.9153 (6.9485)  time: 2.1531  data: 0.0002  max mem: 18364
[05/05 14:13:09] train INFO: Epoch: [0]  [2180/5004]  eta: 1:41:57  lr: 0.000001  loss: 6.9221 (6.9484)  time: 2.1530  data: 0.0002  max mem: 18364
[05/05 14:13:30] train INFO: Epoch: [0]  [2190/5004]  eta: 1:41:35  lr: 0.000001  loss: 6.9274 (6.9483)  time: 2.1526  data: 0.0001  max mem: 18364
[05/05 14:13:52] train INFO: Epoch: [0]  [2200/5004]  eta: 1:41:13  lr: 0.000001  loss: 6.9217 (6.9481)  time: 2.1532  data: 0.0001  max mem: 18364
[05/05 14:14:13] train INFO: Epoch: [0]  [2210/5004]  eta: 1:40:51  lr: 0.000001  loss: 6.9217 (6.9480)  time: 2.1541  data: 0.0001  max mem: 18364
[05/05 14:14:35] train INFO: Epoch: [0]  [2220/5004]  eta: 1:40:29  lr: 0.000001  loss: 6.9242 (6.9479)  time: 2.1536  data: 0.0001  max mem: 18364
[05/05 14:14:56] train INFO: Epoch: [0]  [2230/5004]  eta: 1:40:07  lr: 0.000001  loss: 6.9227 (6.9478)  time: 2.1547  data: 0.0001  max mem: 18364
[05/05 14:15:18] train INFO: Epoch: [0]  [2240/5004]  eta: 1:39:46  lr: 0.000001  loss: 6.9225 (6.9477)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 14:15:39] train INFO: Epoch: [0]  [2250/5004]  eta: 1:39:24  lr: 0.000001  loss: 6.9176 (6.9476)  time: 2.1520  data: 0.0002  max mem: 18364
[05/05 14:16:01] train INFO: Epoch: [0]  [2260/5004]  eta: 1:39:02  lr: 0.000001  loss: 6.9176 (6.9475)  time: 2.1532  data: 0.0002  max mem: 18364
[05/05 14:16:23] train INFO: Epoch: [0]  [2270/5004]  eta: 1:38:40  lr: 0.000001  loss: 6.9324 (6.9474)  time: 2.1541  data: 0.0002  max mem: 18364
[05/05 14:16:44] train INFO: Epoch: [0]  [2280/5004]  eta: 1:38:18  lr: 0.000001  loss: 6.9203 (6.9473)  time: 2.1537  data: 0.0002  max mem: 18364
[05/05 14:17:06] train INFO: Epoch: [0]  [2290/5004]  eta: 1:37:57  lr: 0.000001  loss: 6.9191 (6.9472)  time: 2.1553  data: 0.0001  max mem: 18364
[05/05 14:17:27] train INFO: Epoch: [0]  [2300/5004]  eta: 1:37:35  lr: 0.000001  loss: 6.9273 (6.9471)  time: 2.1543  data: 0.0001  max mem: 18364
[05/05 14:17:49] train INFO: Epoch: [0]  [2310/5004]  eta: 1:37:13  lr: 0.000001  loss: 6.9179 (6.9469)  time: 2.1531  data: 0.0001  max mem: 18364
[05/05 14:18:10] train INFO: Epoch: [0]  [2320/5004]  eta: 1:36:51  lr: 0.000001  loss: 6.9199 (6.9469)  time: 2.1539  data: 0.0002  max mem: 18364
[05/05 14:18:32] train INFO: Epoch: [0]  [2330/5004]  eta: 1:36:30  lr: 0.000001  loss: 6.9279 (6.9468)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 14:18:53] train INFO: Epoch: [0]  [2340/5004]  eta: 1:36:08  lr: 0.000001  loss: 6.9135 (6.9467)  time: 2.1542  data: 0.0001  max mem: 18364
[05/05 14:19:15] train INFO: Epoch: [0]  [2350/5004]  eta: 1:35:46  lr: 0.000001  loss: 6.9132 (6.9466)  time: 2.1543  data: 0.0001  max mem: 18364
[05/05 14:19:36] train INFO: Epoch: [0]  [2360/5004]  eta: 1:35:24  lr: 0.000001  loss: 6.9111 (6.9464)  time: 2.1541  data: 0.0001  max mem: 18364
[05/05 14:19:58] train INFO: Epoch: [0]  [2370/5004]  eta: 1:35:02  lr: 0.000001  loss: 6.9201 (6.9463)  time: 2.1542  data: 0.0001  max mem: 18364
[05/05 14:20:20] train INFO: Epoch: [0]  [2380/5004]  eta: 1:34:41  lr: 0.000001  loss: 6.9268 (6.9463)  time: 2.1545  data: 0.0002  max mem: 18364
[05/05 14:20:41] train INFO: Epoch: [0]  [2390/5004]  eta: 1:34:19  lr: 0.000001  loss: 6.9213 (6.9461)  time: 2.1544  data: 0.0002  max mem: 18364
[05/05 14:21:03] train INFO: Epoch: [0]  [2400/5004]  eta: 1:33:57  lr: 0.000001  loss: 6.9186 (6.9460)  time: 2.1525  data: 0.0002  max mem: 18364
[05/05 14:21:24] train INFO: Epoch: [0]  [2410/5004]  eta: 1:33:35  lr: 0.000001  loss: 6.9255 (6.9459)  time: 2.1528  data: 0.0001  max mem: 18364
[05/05 14:21:46] train INFO: Epoch: [0]  [2420/5004]  eta: 1:33:14  lr: 0.000001  loss: 6.9131 (6.9458)  time: 2.1554  data: 0.0001  max mem: 18364
[05/05 14:22:07] train INFO: Epoch: [0]  [2430/5004]  eta: 1:32:52  lr: 0.000001  loss: 6.9161 (6.9457)  time: 2.1544  data: 0.0002  max mem: 18364
[05/05 14:22:29] train INFO: Epoch: [0]  [2440/5004]  eta: 1:32:30  lr: 0.000001  loss: 6.9161 (6.9456)  time: 2.1517  data: 0.0002  max mem: 18364
[05/05 14:22:50] train INFO: Epoch: [0]  [2450/5004]  eta: 1:32:08  lr: 0.000001  loss: 6.9179 (6.9455)  time: 2.1524  data: 0.0002  max mem: 18364
[05/05 14:23:12] train INFO: Epoch: [0]  [2460/5004]  eta: 1:31:46  lr: 0.000001  loss: 6.9170 (6.9453)  time: 2.1527  data: 0.0002  max mem: 18364
[05/05 14:23:33] train INFO: Epoch: [0]  [2470/5004]  eta: 1:31:25  lr: 0.000001  loss: 6.9195 (6.9452)  time: 2.1532  data: 0.0002  max mem: 18364
[05/05 14:23:55] train INFO: Epoch: [0]  [2480/5004]  eta: 1:31:03  lr: 0.000001  loss: 6.9227 (6.9451)  time: 2.1526  data: 0.0001  max mem: 18364
[05/05 14:24:16] train INFO: Epoch: [0]  [2490/5004]  eta: 1:30:41  lr: 0.000001  loss: 6.9066 (6.9450)  time: 2.1523  data: 0.0002  max mem: 18364
[05/05 14:24:38] train INFO: Epoch: [0]  [2500/5004]  eta: 1:30:19  lr: 0.000001  loss: 6.9066 (6.9449)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 14:24:59] train INFO: Epoch: [0]  [2510/5004]  eta: 1:29:58  lr: 0.000001  loss: 6.9047 (6.9447)  time: 2.1540  data: 0.0002  max mem: 18364
[05/05 14:25:21] train INFO: Epoch: [0]  [2520/5004]  eta: 1:29:36  lr: 0.000001  loss: 6.9088 (6.9446)  time: 2.1519  data: 0.0002  max mem: 18364
[05/05 14:25:43] train INFO: Epoch: [0]  [2530/5004]  eta: 1:29:14  lr: 0.000001  loss: 6.9182 (6.9445)  time: 2.1525  data: 0.0001  max mem: 18364
[05/05 14:26:04] train INFO: Epoch: [0]  [2540/5004]  eta: 1:28:52  lr: 0.000001  loss: 6.9222 (6.9444)  time: 2.1557  data: 0.0002  max mem: 18364
[05/05 14:26:26] train INFO: Epoch: [0]  [2550/5004]  eta: 1:28:31  lr: 0.000001  loss: 6.9164 (6.9443)  time: 2.1549  data: 0.0002  max mem: 18364
[05/05 14:26:47] train INFO: Epoch: [0]  [2560/5004]  eta: 1:28:09  lr: 0.000001  loss: 6.9163 (6.9442)  time: 2.1535  data: 0.0002  max mem: 18364
[05/05 14:27:09] train INFO: Epoch: [0]  [2570/5004]  eta: 1:27:47  lr: 0.000001  loss: 6.9093 (6.9441)  time: 2.1533  data: 0.0001  max mem: 18364
[05/05 14:27:30] train INFO: Epoch: [0]  [2580/5004]  eta: 1:27:25  lr: 0.000001  loss: 6.9194 (6.9440)  time: 2.1533  data: 0.0002  max mem: 18364
[05/05 14:27:52] train INFO: Epoch: [0]  [2590/5004]  eta: 1:27:04  lr: 0.000001  loss: 6.9231 (6.9439)  time: 2.1529  data: 0.0001  max mem: 18364
[05/05 14:28:13] train INFO: Epoch: [0]  [2600/5004]  eta: 1:26:42  lr: 0.000001  loss: 6.9159 (6.9438)  time: 2.1540  data: 0.0001  max mem: 18364
[05/05 14:28:35] train INFO: Epoch: [0]  [2610/5004]  eta: 1:26:20  lr: 0.000001  loss: 6.9147 (6.9437)  time: 2.1543  data: 0.0002  max mem: 18364
[05/05 14:28:56] train INFO: Epoch: [0]  [2620/5004]  eta: 1:25:58  lr: 0.000001  loss: 6.9208 (6.9436)  time: 2.1532  data: 0.0002  max mem: 18364
[05/05 14:29:18] train INFO: Epoch: [0]  [2630/5004]  eta: 1:25:37  lr: 0.000001  loss: 6.9231 (6.9436)  time: 2.1546  data: 0.0002  max mem: 18364
[05/05 14:29:39] train INFO: Epoch: [0]  [2640/5004]  eta: 1:25:15  lr: 0.000001  loss: 6.9231 (6.9435)  time: 2.1545  data: 0.0001  max mem: 18364
[05/05 14:30:01] train INFO: Epoch: [0]  [2650/5004]  eta: 1:24:53  lr: 0.000001  loss: 6.9112 (6.9434)  time: 2.1522  data: 0.0001  max mem: 18364
[05/05 14:30:23] train INFO: Epoch: [0]  [2660/5004]  eta: 1:24:32  lr: 0.000001  loss: 6.9065 (6.9433)  time: 2.1526  data: 0.0001  max mem: 18364
[05/05 14:30:44] train INFO: Epoch: [0]  [2670/5004]  eta: 1:24:10  lr: 0.000001  loss: 6.9171 (6.9432)  time: 2.1539  data: 0.0001  max mem: 18364
[05/05 14:31:06] train INFO: Epoch: [0]  [2680/5004]  eta: 1:23:48  lr: 0.000001  loss: 6.9074 (6.9431)  time: 2.1522  data: 0.0001  max mem: 18364
[05/05 14:31:27] train INFO: Epoch: [0]  [2690/5004]  eta: 1:23:26  lr: 0.000001  loss: 6.9082 (6.9430)  time: 2.1523  data: 0.0001  max mem: 18364
[05/05 14:31:49] train INFO: Epoch: [0]  [2700/5004]  eta: 1:23:05  lr: 0.000001  loss: 6.9104 (6.9429)  time: 2.1523  data: 0.0001  max mem: 18364
[05/05 14:32:16] train INFO: Namespace(fp32_resume=False, batch_size=128, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=24, pin_mem=True, world_size=2, dist_url='env://', token_label=False, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 14:32:17] train INFO: Creating model: simba_s
[05/05 14:32:24] train INFO: number of params: 26142088
[05/05 14:32:24] train INFO: Start training for 310 epochs
[05/05 14:32:53] train INFO: Epoch: [0]  [   0/5004]  eta: 1 day, 16:38:48  lr: 0.000001  loss: 7.0223 (7.0223)  time: 29.2422  data: 1.3652  max mem: 18147
[05/05 14:33:15] train INFO: Epoch: [0]  [  10/5004]  eta: 6:24:44  lr: 0.000001  loss: 6.9799 (6.9789)  time: 4.6223  data: 0.1242  max mem: 18364
[05/05 14:33:37] train INFO: Epoch: [0]  [  20/5004]  eta: 4:46:14  lr: 0.000001  loss: 6.9799 (6.9852)  time: 2.1561  data: 0.0001  max mem: 18364
[05/05 14:33:58] train INFO: Epoch: [0]  [  30/5004]  eta: 4:11:04  lr: 0.000001  loss: 7.0052 (6.9938)  time: 2.1522  data: 0.0001  max mem: 18364
[05/05 14:34:20] train INFO: Epoch: [0]  [  40/5004]  eta: 3:52:56  lr: 0.000001  loss: 6.9961 (6.9927)  time: 2.1536  data: 0.0001  max mem: 18364
[05/05 14:34:41] train INFO: Epoch: [0]  [  50/5004]  eta: 3:41:45  lr: 0.000001  loss: 6.9732 (6.9916)  time: 2.1543  data: 0.0001  max mem: 18364
[05/05 14:35:03] train INFO: Epoch: [0]  [  60/5004]  eta: 3:34:07  lr: 0.000001  loss: 6.9732 (6.9928)  time: 2.1538  data: 0.0002  max mem: 18364
[05/05 14:35:24] train INFO: Epoch: [0]  [  70/5004]  eta: 3:28:32  lr: 0.000001  loss: 6.9882 (6.9926)  time: 2.1540  data: 0.0002  max mem: 18364
[05/05 14:35:46] train INFO: Epoch: [0]  [  80/5004]  eta: 3:24:13  lr: 0.000001  loss: 6.9925 (6.9924)  time: 2.1528  data: 0.0001  max mem: 18364
[05/05 14:36:07] train INFO: Epoch: [0]  [  90/5004]  eta: 3:20:48  lr: 0.000001  loss: 6.9841 (6.9908)  time: 2.1533  data: 0.0001  max mem: 18364
[05/05 15:01:04] train INFO: Namespace(fp32_resume=False, batch_size=256, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=12, pin_mem=True, world_size=2, dist_url='env://', token_label=False, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 15:01:05] train INFO: Creating model: simba_s
[05/05 15:01:13] train INFO: number of params: 26142088
[05/05 15:01:13] train INFO: Start training for 310 epochs
[05/05 15:02:05] train INFO: Epoch: [0]  [   0/2502]  eta: 1 day, 12:18:32  lr: 0.000001  loss: 6.9970 (6.9970)  time: 52.2431  data: 2.6093  max mem: 35851
[05/05 15:02:50] train INFO: Epoch: [0]  [  10/2502]  eta: 6:07:26  lr: 0.000001  loss: 6.9926 (6.9902)  time: 8.8470  data: 0.2373  max mem: 35963
[05/05 15:03:35] train INFO: Epoch: [0]  [  20/2502]  eta: 4:40:23  lr: 0.000001  loss: 6.9886 (6.9936)  time: 4.5051  data: 0.0001  max mem: 35963
[05/05 15:04:20] train INFO: Epoch: [0]  [  30/2502]  eta: 4:09:03  lr: 0.000001  loss: 6.9924 (6.9928)  time: 4.5038  data: 0.0001  max mem: 35963
[05/05 15:05:05] train INFO: Epoch: [0]  [  40/2502]  eta: 3:52:34  lr: 0.000001  loss: 6.9999 (6.9942)  time: 4.5022  data: 0.0002  max mem: 35963
[05/05 15:05:50] train INFO: Epoch: [0]  [  50/2502]  eta: 3:42:11  lr: 0.000001  loss: 6.9892 (6.9936)  time: 4.4950  data: 0.0002  max mem: 35963
[05/05 15:06:35] train INFO: Epoch: [0]  [  60/2502]  eta: 3:34:59  lr: 0.000001  loss: 6.9883 (6.9925)  time: 4.4920  data: 0.0001  max mem: 35963
[05/05 15:07:20] train INFO: Epoch: [0]  [  70/2502]  eta: 3:29:38  lr: 0.000001  loss: 6.9765 (6.9907)  time: 4.4965  data: 0.0001  max mem: 35963
[05/05 15:08:05] train INFO: Epoch: [0]  [  80/2502]  eta: 3:25:26  lr: 0.000001  loss: 6.9884 (6.9913)  time: 4.4998  data: 0.0001  max mem: 35963
[05/05 15:08:50] train INFO: Epoch: [0]  [  90/2502]  eta: 3:21:58  lr: 0.000001  loss: 6.9974 (6.9904)  time: 4.5001  data: 0.0001  max mem: 35963
[05/05 15:09:46] train INFO: Namespace(fp32_resume=False, batch_size=256, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=12, pin_mem=True, world_size=2, dist_url='env://', token_label=False, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 15:09:47] train INFO: Creating model: simba_s
[05/05 15:09:53] train INFO: number of params: 26142088
[05/05 15:09:53] train INFO: Start training for 310 epochs
[05/05 15:19:10] train INFO: Namespace(fp32_resume=False, batch_size=256, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=12, pin_mem=True, world_size=2, dist_url='env://', token_label=False, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 15:19:11] train INFO: Creating model: simba_s
[05/05 15:19:17] train INFO: number of params: 26142088
[05/05 15:19:17] train INFO: Start training for 310 epochs
[05/05 15:19:58] train INFO: Namespace(fp32_resume=False, batch_size=256, epochs=310, config='config/simba_s.py', model='simba_s', input_size=224, drop=0.0, drop_path=0.1, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='dataset/ILSVRC2012', data_set='IMNET', use_mcloader=False, inat_category='name', output_dir='checkpoints/simba_s', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=12, pin_mem=True, world_size=2, dist_url='env://', token_label=False, token_label_data='', token_label_size=1, dense_weight=0.5, cls_weight=1.0, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, use_multi_epochs_loader=False, rank=1, gpu=1, distributed=True, dist_backend='nccl')
[05/05 15:19:59] train INFO: Creating model: simba_s
[05/05 15:20:05] train INFO: number of params: 26142088
[05/05 15:20:05] train INFO: Start training for 310 epochs
[05/05 15:20:57] train INFO: Epoch: [0]  [   0/2502]  eta: 1 day, 11:53:29  lr: 0.000001  data_time: 2.9719  compute_time: 2.9677  loss: 6.9972 (6.9972)  time: 51.6425  data: 2.9719  max mem: 28757
[05/05 15:21:40] train INFO: Epoch: [0]  [  10/2502]  eta: 6:00:22  lr: 0.000001  data_time: 0.0002  compute_time: 0.0238  loss: 6.9906 (6.9899)  time: 8.6768  data: 0.2703  max mem: 28859
[05/05 15:22:24] train INFO: Epoch: [0]  [  20/2502]  eta: 4:34:27  lr: 0.000001  data_time: 0.0002  compute_time: 0.0136  loss: 6.9893 (6.9935)  time: 4.3843  data: 0.0001  max mem: 28859
[05/05 15:23:08] train INFO: Epoch: [0]  [  30/2502]  eta: 4:03:26  lr: 0.000001  data_time: 0.0002  compute_time: 0.0136  loss: 6.9932 (6.9927)  time: 4.3864  data: 0.0001  max mem: 28859
[05/05 15:23:52] train INFO: Epoch: [0]  [  40/2502]  eta: 3:47:14  lr: 0.000001  data_time: 0.0002  compute_time: 0.0135  loss: 6.9995 (6.9942)  time: 4.3861  data: 0.0001  max mem: 28859
[05/05 15:24:36] train INFO: Epoch: [0]  [  50/2502]  eta: 3:37:05  lr: 0.000001  data_time: 0.0002  compute_time: 0.0137  loss: 6.9894 (6.9936)  time: 4.3876  data: 0.0001  max mem: 28859
[05/05 15:25:20] train INFO: Epoch: [0]  [  60/2502]  eta: 3:30:03  lr: 0.000001  data_time: 0.0002  compute_time: 0.0137  loss: 6.9880 (6.9925)  time: 4.3886  data: 0.0001  max mem: 28859
[05/05 15:26:04] train INFO: Epoch: [0]  [  70/2502]  eta: 3:24:45  lr: 0.000001  data_time: 0.0002  compute_time: 0.0137  loss: 6.9756 (6.9907)  time: 4.3866  data: 0.0001  max mem: 28859
